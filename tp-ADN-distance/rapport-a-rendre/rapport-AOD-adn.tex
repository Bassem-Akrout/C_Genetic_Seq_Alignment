\documentclass[10pt,a4paper]{article}

\usepackage[latin1]{inputenc}
%\usepackage[T1]{fontenc}
\usepackage{enumerate}

%%%% POUR FAIRE TENIR SUR UNE PAGE RECTO-VERSO.....
\textwidth 18.5cm
\oddsidemargin -1.75cm
\evensidemargin -1.75cm
\textheight 28.0cm
\topmargin -3.0cm

%   \textwidth 18cm
   %\oddsidemargin -1.5cm
   %\evensidemargin -1.5cm
   %\textheight 26.0cm
   %\topmargin -2.0cm


\begin{document}

\thispagestyle{empty}

\noindent\centerline{\bf\large Questionnaire TP AOD 2023-2024 à compléter et rendre sur Teide}
Binôme (Akrout Bassem -- Khalfallah Firas)

\section{Préambule (1 point)}
Le programme récursif avec mémorisation fourni alloue une mémoire de taille $N \cdot M$. Il génère une erreur d'exécution sur le test 5 (ci-dessous). Pourquoi ?
Réponse: Le programme atteint la profondeur maximale de récursion (max recursion depth), entraînant un débordement de pile (stack overflow). Cela se produit lorsque la récursion s'empile trop profondément, dépassant les limites de la pile de mémoire du système.
\begin{verbatim}
distanceEdition-recmemo GCA_024498555.1_ASM2449855v1_genomic.fna 77328790 20236404 \
                        GCF_000001735.4_TAIR10.1_genomic.fna 30808129 19944517
\end{verbatim}

%%%%%%%%%%%%%%%%%%%
{\noindent\bf{Important.} Dans toute la suite, on demande des programmes qui allouent un espace mémoire $O(N+M)$.}

\section{Programme itératif en espace mémoire $O(N+M)$ (5 points)}
{\em Expliquer très brièvement (2 à 5 lignes max) le principe de votre code, la mémoire utilisée, le sens de parcours des tableaux.}

Une file (deque) de taille O(N+1) est créée pour stocker temporairement les valeurs calculées pendant l'algorithme.
Le code remplit la dernière ligne de la matrice de coût (Ø) avec les valeurs appropriées, commençant par l'indice le plus grand et se déplaçant vers l'indice le plus petit.
Le code remplit la matrice ligne par ligne en utilisant la file deque pour stocker temporairement les valeurs nécessaires, en supprimant les valeurs dont on n'a plus besoin au fur et à mesure, tout en prenant soin de gérer les cas particuliers.
Analyse du coût théorique de ce programme en fonction de $N$ et $M$ en notation $\Theta(...)$
\begin{enumerate}
  \item Place mémoire allouée (ne pas compter les 2 séquences $X$ et $Y$ en mémoire via {\tt mmap}) :$\Theta( 3 \times(M + 1) \times sizeof(queueNode))$\\( la multiplication par 3 représente le fait que queueNode contient trois attributs dans la structure
  value / prev / next ) \\
  \item Travail (nombre d'opérations) :$\Theta(M * N * f)$, où f représente le coût des opérations internes dans chaque itération de la troisième boucle.(pushBack, popFront, isBase, ManageBaseError)
  \item Nombre de défauts de cache obligatoires (sur modèle CO, y compris sur $X$ et $Y$): $\frac{3 \times (M + 1)}{L} +\frac{N + M}{L}$ = $\frac{(3 \times N) + M}{L}$
  \item Nombre de défauts de cache si $Z \ll \min(N,M)$ : $\frac{3 \times N M}{L} +\frac{N + M}{L}$ 
\end{enumerate}

%%%%%%%%%%%%%%%%%%%
\section{Programme cache-aware (3 points)}
{\em Expliquer très brièvement (2 à 5 lignes max) le principe de votre code, la mémoire utilisée, le sens de parcours des tableaux.}
\\
Une file (queueBlock) de taille O(N+1) est créée pour stocker temporairement les files "queue" contenant les valeurs calculées par l'algorithme utilisées par la suite
Le code remplit le bloc en bas à droite puis les blocs en bas en utilisant les fonctions block_down_right et block_down. \\
le code remplit les lignes des blocs restants ligne par ligne en commençant par la droite en utilisant
les fonctions block_right et block \\

Analyse du coût théorique de ce programme en fonction de $N$ et $M$ en notation $\Theta(...)$
\begin{enumerate}
  \item Place mémoire (ne pas compter les 2 séquences initiales $X$ et $Y$ en mémoire via {\tt mmap}) : $\Theta(3 \times(M+1)\times sizeof(queueNode))$
  \item Travail (nombre d'opérations) : $\Theta(M * N * f + M * g )$, où f représente le coût des opérations internes dans chaque itération (pushBack, popFront, isBase, ManageBaseError) et g représente le coût des opérations internes dans chaque itération (pushBackBlock, popFrontBlock) \\
  \item Nombre de défauts de cache obligatoires (sur modèle CO, y compris sur $X$ et $Y$): $\frac{3 \times (M + 1)}{L} +\frac{N + M}{L} + \frac{N* M}{K^2}$ = $\frac{(3 \times N) + M}{L} + \frac{N* M * L}{Z} $ \\
  \item Nombre de défauts de cache si $Z \ll \min(N,M)$ : $\frac{3 \times N M}{L} +\frac{N + M}{L} + \frac{N* M * L}{Z}$ \\
\end{enumerate}

%%%%%%%%%%%%%%%%%%%
\section{Programme cache-oblivious (3 points)}
{\em Expliquer très brièvement (2 à 5 lignes max) le principe de votre code, la mémoire utilisée, le sens de parcours des tableaux.}
Le programme crée un dictionnaire qui contient des paires ((i,j), valeur) qui représentent les valeurs de la matrice de calcul de distance d'édition.\\
on remplit le dictionnaire récursivement en tachant de supprimer toutes informations dans le dictionnaire inutiles pour la suite du calcul. \\
Analyse du coût théorique de ce programme en fonction de $N$ et $M$ en notation $\Theta(...)$
\begin{enumerate}
  \item Place mémoire (ne pas compter les 2 séquences initiales $X$ et $Y$ en mémoire via {\tt mmap}) : $\Theta( 3 \times(M + 1)\times sizeof(HashNode))$
  \item Travail (nombre d'opérations) : $\Theta(M * N * f)$, où f représente le coût de findInHashTable, addToHashTable et removeFromHashTable.\\ 
  \item Nombre de défauts de cache obligatoires (sur modèle CO, y compris sur $X$ et $Y$): $ \frac{ (M+1)}{L} $ (En supposant que la distribution des 
  données dans la hashtable est idéale mais ce n'est pas le cas. Ce qui provoque des défauts de cache en plus. \\
  En effet la table de hashage ne permet pas de réutiliser les mêmes zones de mémoire et donc ne permet pas une localité idéale dans le cache ) \\
  \item Nombre de défauts de cache si $Z \ll \min(N,M)$ : $ \frac{3 \times (M N)}{L} $
\end{enumerate}

\section{Réglage du seuil d'arrêt récursif du programme cache-oblivious (1 point)}
Comment faites-vous sur une machine donnée pour choisir ce seuil d'arrêt ? Quelle valeur avez-vous choisie pour les PC de l'Ensimag ? \\
Puisqu'on utilise un dictionnaire, on suppose que les données sont non-contigües donc on prend $ S = \sqrt(\frac{Z}{L}) = 8 $

%%%%%%%%%%%%%%%%%%%
\section{Expérimentation (7 points)}

Description de la machine d'expérimentation: \textbf{ENSIPC}\\
Processeur: \textbf{Intel(R) Core(TM) i5-8500 CPU @ 3.00GHz}\\
Mémoire: \textbf{total        used        free      shared  buff/cache   available
          31Gi       2.7Gi        24Gi       101Mi       3.7Gi        27Gi}\\
Système: \textbf{Linux ensipc}\\

\subsection{(3 points) Avec {\tt valgrind --tool=cachegrind --D1=4096,4,64}}
\begin{verbatim}
     distanceEdition ba52_recent_omicron.fasta 153 N wuhan_hu_1.fasta 116 M
\end{verbatim}
en prenant pour $N$ et $M$ les valeurs dans le tableau ci-dessous.

Les paramètres du cache LL de second niveau sont :\\ \textbf{Caches (sum of all):     
L1d:                   192 KiB (6 instances)
L1i:                   192 KiB (6 instances)
L2:                    1.5 MiB (6 instances)
L3(cache LL):          9 MiB (1 instance)
}

{\em Le tableau ci-dessous est un exemple, complété avec vos résultats et ensuite analysé.}
\\
{\footnotesize
\begin{tabular}{|r|r||r|r|r||r|r|r||r|r|r||r|r|r||}
\hline
 \multicolumn{2}{|c||}{ } 
& \multicolumn{3}{c||}{récursif mémorisation}
& \multicolumn{3}{c||}{itératif}
\\ \hline
N & M 
& \#Irefs & \#Drefs & \#D1miss % récursif mémorisation
& \#Irefs & \#Drefs & \#D1miss % itératif

\\ \hline
\hline
1000 & 1000 
& 217,203,381  & 122,122,977  & 4,926,135  % récursif mémorisation
& 284,358,531 & 155,331,347 & 578,335  % itératif

\\ \hline
2000 & 1000 
& 433,380,775  & 243,402,209 & 11,023,544  % récursif mémorisation
& 567,323,621 & 309,674,249 & 1,161,412  % itératif

\\ \hline
4000 & 1000 
& 867,152,873 & 487,366,465  & 23,223,565   % récursif mémorisation
& 1,134,655,043 & 619,761,667  & 2,341,695  % itératif

\\ \hline
2000 & 2000 
& 867,144,471  & 487,889,160  & 19,897,963   % récursif mémorisation
& 1,135,525,159 & 620,589,183 & 2,277,473  % itératif

\\ \hline
4000 & 4000 
& 3,465,867,184 & 1,950,549,355 & 80,000,793   % récursif mémorisation
& 4,538,899,295 & 2,481,068,095 & 9,052,182  % itératif

\\ \hline
6000 & 6000 
& 7,796,327,646 & 4,387,985,166 & 180,336,505  % récursif mémorisation
& 10,210,328,397 & 5,581,498,353 & 20,340,277  % itératif

\\ \hline
8000 & 8000 
& 10,376,405,159 & 5,832,061,863 & 253,320,528  % récursif mémorisation
& 13,594,369,368 & 7,423,143,738  & 27,256,873  % itératif

\\ \hline
\hline
\end{tabular}
}

\begin{tabular}{|r|r||r|r|r||r|r|r||r|r|r||r|r|r||}
  \hline
   \multicolumn{2}{|c||}{ }
   & \multicolumn{3}{c||}{cache-aware}
& \multicolumn{3}{c||}{cache-oblivious}
\\ \hline
N & M 

& \#Irefs & \#Drefs & \#D1miss % cache-aware
& \#Irefs & \#Drefs & \#D1miss % cache-oblivious
\\ \hline
\hline
1000 & 1000 
& 369,905,217 & 197,863,313 & 865,243  % cache-aware
& 618,060,328 & 354,059,807 & 6,569,751  % cache-oblivious
\\ \hline
2000 & 1000 

& 738,517,447 & 394,781,687 & 1,720,062  % cache-aware
& 1,234,428,836 & 706,917,103  & 12,822,265   % cache-oblivious
\\ \hline
4000 & 1000 
& 1,477,150,263 & 790,022,341  & 3,412,020   % cache-aware
& 2,468,581,134 & 1,414,044,384 & 26,333,648   % cache-oblivious
\\ \hline
2000 & 2000 
& 1,477,167,050 & 790,473,989 & 3,353,336   % cache-aware
& 2,469,037,626 & 1,414,784,830 & 26,531,346  % cache-oblivious
\\ \hline
4000 & 4000 

& 5,904,392,298 & 3,160,125,603  & 13,929,861 % cache-aware
&  9,870,498,780 & 5,656,506,344 & 110,123,907  % cache-oblivious
\\ \hline
6000 & 6000 

& 13,281,865,938 &  7,109,004,529 & 31,174,679  % cache-aware
& 22,078,328,952 & 12,704,659,878  & 233,885,516  % cache-oblivious
\\ \hline
8000 & 8000 

& 17,689,915,509 & 9,459,885,099 & 41,625,717  % cache-aware
& 29,586,621,624 & 16,964,557,020 & 309,182,810  % cache-oblivious
\\ \hline
\hline
\end{tabular}


\paragraph{Important : analyse expérimentale}
Ces mesures expérimentales sont-elles en accord avec les coûts analysés théoriquement (justifier) ? 
Quel algorithme se comporte le mieux avec Valgrind et les paramètres proposés, pourquoi ? \\
\\Les mesures expérimentales correspondent (à peu près) à notre analyse théorique . Le programme itératif fait moins de cache miss (malheureusement) que le cache
aware qui à son tour fait moins de cache miss que le cache oblivious .. \\
Les ordres de grandeurs sont à peu près correctes pour le programme itératif . \\  

\subsection{(3 points) Sans Valgrind, par exécution de la commande :}
{\tt \begin{tabular}{llll}
distanceEdition & GCA\_024498555.1\_ASM2449855v1\_genomic.fna & 77328790 & M \\
                & GCF\_000001735.4\_TAIR10.1\_genomic.fna     & 30808129 & N
\end{tabular}}

On mesure le temps écoulé, le temps CPU et l'énergie consommée avec : \\ {\em
\textbf{La mesure a été faite avec l'éxécutable distanceEdition-perf dans le Makefile-test (voir makefile test) : On a ajouté une règle perf-test pour faire tous les
tests nécéssaires sur le temps / énérgie. }

% ou {\tt perfstart/perfstop\_and\_display}%
% \footnote{
%     cf {\tt /matieres/4MMAOD6/2023-10-TP-AOD-ADN-Docs-fournis/tp-ADN-distance/srcperf/0-LisezMoi}
% }
\\

 }

Nota bene : pour avoir un résultat fiable/reproductible (si variabilité), 
il est préférable de faire chaque mesure 5 fois et de reporter l'intervalle
de confiance [min, moyenne, max].

\begin{tabular}{|r|r||r|r|r||r|r|r||r|r|r||}
\hline
 \multicolumn{2}{|c||}{ } 
& \multicolumn{3}{c||}{itératif}
& \multicolumn{3}{c||}{cache-aware}

\\ \hline
N & M 
& temps   & temps & énergie(kWh)      % itératif
& temps   & temps & énergie(kWh)      % cache-aware

\\
& 
& CPU     & écoulé&               % itératif
& CPU     & écoulé&               % cache-aware

\\ \hline
\hline
10000 & 10000 
& 2.81769 & 2.82062  & 1.96746e-05  % itératif
& 3.74311 & 3.90681 & 2.04487e-05  % cache-aware

\\ \hline
20000 & 20000 
& 11.3032 & 11.3034 & 7.32657e-05  % itératif
& 16.9161 & 17.3804 & 9.26128e-05  % cache-aware

\\ \hline
30000 & 30000 
& 25.2021 & 25.2054 & 0.0001414 % itératif
& 36.237 & 37.3177 & 0.0002049  % cache-aware
\\ \hline
40000 & 40000 
& 44.3899  & 44.3903  & 0.0002387  % itératif
& 61.6594 & 63.5406 & 0.0003539 % cache-aware
\\ \hline
\hline
\end{tabular}

\begin{tabular}{|r|r||r|r|r||r|r|r||r|r|r||}
  \hline
   \multicolumn{2}{|c||}{ } 
   & \multicolumn{3}{c||}{cache-oblivious}
   \\ \hline
N & M 

& temps   & temps & énergie(kWh)       % cache-oblivious
\\
& 

& CPU     & écoulé&               % cache-oblivious
\\ \hline
\hline
10000 & 10000 

& 8.96335 & 9.63368  & 5.28187e-05  % cache-oblivious
\\ \hline
20000 & 20000 

& 35.3481 & 35.5167 & 0.0001909  % cache-oblivious
\\ \hline
30000 & 30000 

& 79.7995 & 79.8191 & 0.0003930  % cache-oblivious
\\ \hline
40000 & 40000 

& 142.422 & 142.423 & 0.0007156  % cache-oblivious
\\ \hline
\hline
\end{tabular}

\paragraph{Important : Analyse expérimentale}
Ces mesures expérimentales sont-elles en accord avec les coûts analysés théoriquement ? (justifier)
Quel algorithme se comporte le mieux avec Valgrind et les paramètres proposés, pourquoi ?\\
\\ Vu qu'il y a plus d'opérations , la consommation d'énérgie est plus élevée pour le cache oblivious > cache aware > itératif et on déduit de même pour le temps 
d'éxécution des algorithmes. \\ 
Notre analyse théorique est donc en accord avec l'expérience .\\ 

\subsection{(1 point) Extrapolation : estimation de la durée et de l'énergie pour la commande :}
\begin{tabular}{llll}
    distanceEdition & GCA\_024498555.1\_ASM2449855v1\_genomic.fna & 77328790 & 20236404 \\
    & GCF\_000001735.4\_TAIR10.1\_genomic.fna & 30808129 & 19944517
\end{tabular}

\\ \textbf{Après avoir élaboré nos algorithmes et en testant le dernier test sur les longueurs respectives 10000 , 20000, 30000, 40000 , On a créé un petit programme python
qui permet de faire une régression linéaire simple pour savoir le temps d'éxécution pour des valeurs très grandes de longueurs de séquences génétiques (similaires à celles du test5): Vous pouvez trouver
le code python dans le dossier ./src .. } \\
\\ À partir des résultats précédents du script python et de l'éxécution de nos algorithmes, le programme \emph{itératif} est le plus performant pour la commande ci-dessus (test 5). Les ressources pour l'exécution seraient environ :
\begin{itemize}
    \item Temps CPU (en h) : 25heures .. 
    \item Énergie (en kWh) : ~ 0.1466 kWh ..  
\end{itemize}

Question subsidiaire : comment feriez-vous pour avoir un programme s'exécutant en moins d'1 minute ?
\emph{Le parallélisme ! }

\end{document}
